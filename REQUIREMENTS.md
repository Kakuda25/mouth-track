# 口の動きトラッキングモジュール - 要件定義書

## プロジェクト概要

### 目的
口の動きをリアルタイムでトラッキングし、**母音の口の形になっているかをチェックする機能**を提供する、再利用可能なJavaScriptモジュール。

### 背景
- Reactアプリケーションを想定しているが、汎用的に使用可能なモジュールとして設計
- 他のフレームワーク（Vue.js、Angular、Vanilla JS等）からも利用可能
- 教育用途（発音練習、言語学習）やリハビリテーション支援への応用を想定

### ゴール
1. **モジュール化**: 他のアプリケーションから簡単に組み込める再利用可能なモジュール
2. **母音判別**: 日本語の5つの母音（あ、い、う、え、お）の口の形を判別
3. **汎用性**: React、Vue.js、Vanilla JS等、様々な環境で使用可能
4. **拡張性**: 将来的に他の言語の母音や子音の判別にも対応可能な設計

## 機能要件

### F001: 口の動きトラッキング機能

#### F001-1: カメラアクセス
- **概要**: デバイスのカメラにアクセスし、リアルタイム映像を取得
- **詳細**:
  - 内蔵カメラまたは外部USBカメラへのアクセス
  - カメラ権限の取得と管理
  - 複数カメラがある場合の選択機能
  - カメラの起動・停止制御

#### F001-2: 顔・口検出
- **概要**: MediaPipe FaceMeshを使用した高精度な顔・口検出
- **詳細**:
  - リアルタイムでの顔認識（30fps以上）
  - 口周辺のランドマーク検出（16点：`MOUTH_CONTOUR_INDICES`を使用）
    - 上唇外側（7点）
    - 上唇内側（5点）
    - 下唇内側（5点）
    - 口角（2点）
  - 顔が検出できない場合の警告表示
  - 複数人がいる場合の対処（メインの顔を1つ選択）

#### F001-3: ランドマークデータの取得
- **概要**: 検出された口のランドマーク座標を取得
- **詳細**:
  - 16点の2D座標（x, y, z）のリアルタイム取得（`MOUTH_CONTOUR_INDICES`）
  - 座標の正規化（画面サイズに依存しない相対座標）
  - タイムスタンプ付きデータ
  - 座標の平滑化（ノイズ除去）

#### F001-4: 口の形状計測
- **概要**: ランドマークデータから口の形状を数値化
- **詳細**:
  - **高精度計測**: `MOUTH_CONTOUR_INDICES`（16点）を使用した詳細な計測
  - **開き具合（openness）**: 上唇外側と下唇外側の平均点間の距離
  - **幅（width）**: 口角（左端と右端）の距離
  - **面積（area）**: 口の面積の推定値（楕円近似）
  - **アスペクト比（aspectRatio）**: 幅/開き具合（横長か縦長かの指標）
  - **変化率**: 各値の時間変化率

### F002: 母音判別機能（新規）

#### F002-1: 母音の特徴量抽出
- **概要**: 口の形状から母音判別に必要な特徴量を抽出
- **詳細**:
  - **生の計測値を使用**: 正規化せず、生の計測値をそのまま使用（相対判定方式）
  - **開き具合（openness）**: 生の距離値（通常0.01-0.15程度）
  - **幅（width）**: 生の距離値（通常0.03-0.15程度）
  - **アスペクト比（aspectRatio）**: 幅/開き具合（絶対値）
  - **面積（area）**: 生の面積値
  - 口の形状タイプ（縦長、横長、丸い、すぼめ）

#### F002-2: 母音分類
- **概要**: 抽出した特徴量から5つの母音（あ、い、う、え、お）を判別（相対判定方式）
- **詳細**:
  - **相対判定方式**: 生の計測値を正規化せず、相対的な特徴量で判定
  - **「あ」**: 開き具合が大きい（0.06-0.15）、アスペクト比が小さい（0.5-0.8、縦長）
  - **「い」**: 開き具合が小さい（0.0-0.03）、幅が大きい（0.08-0.15）、アスペクト比が大きい（2.0-5.0、横長）
  - **「う」**: 開き具合が小さい（0.0-0.02）、幅が小さい（0.03-0.06）、アスペクト比が中程度（1.5-3.0、すぼめる）
  - **「え」**: 開き具合が中程度（0.03-0.05）、幅が大きい（0.07-0.12）、アスペクト比が大きい（1.5-2.5、横に広げる）
  - **「お」**: 開き具合が中程度（0.05-0.08）、幅が中程度（0.05-0.10）、アスペクト比が小さい（0.9-1.5、丸い）
  - 判別結果の信頼度スコア（0.0 〜 1.0）
  - 各母音のスコアと確率分布を返す

#### F002-3: 判別結果の提供
- **概要**: 判別結果をコールバック関数またはイベントで提供
- **詳細**:
  - 判別された母音（あ、い、う、え、お、または「不明」）
  - 信頼度スコア
  - 各母音の確率分布（5つの母音それぞれの確率）
  - 使用された特徴量の値

#### F002-4: 閾値のカスタマイズ
- **概要**: ユーザーごとの口の形状の違いに対応するため、閾値を調整可能
- **詳細**:
  - 各母音の判別閾値を設定可能（`setThresholds`メソッド）
  - **相対判定方式**: キャリブレーション不要（生の計測値で相対的に判定）
  - 設定の保存・読み込み（将来的な拡張）

### F003: モジュールAPI

#### F003-1: 初期化API
- **概要**: モジュールの初期化と設定
- **詳細**:
  - カメラ設定（解像度、フレームレート）
  - MediaPipe設定（検出精度、信頼度閾値）
  - 母音判別の閾値設定
  - コールバック関数の登録

#### F003-2: トラッキング制御API
- **概要**: トラッキングの開始・停止
- **詳細**:
  - `start()`: トラッキング開始
  - `stop()`: トラッキング停止
  - `pause()`: 一時停止
  - `resume()`: 再開

#### F003-3: データ取得API
- **概要**: リアルタイムデータの取得
- **詳細**:
  - ランドマーク座標の取得
  - 計測値（開き具合、幅、面積等）の取得
  - 母音判別結果の取得
  - イベントリスナーによる通知

#### F003-4: 設定変更API
- **概要**: 実行時の設定変更
- **詳細**:
  - 母音判別閾値の変更
  - 平滑化パラメータの変更
  - カメラの切り替え

### F004: デモ・サンプル機能

#### F004-1: カメラ機能のデモ
- **概要**: モジュールの動作を確認するための見本アプリケーション
- **詳細**:
  - カメラ映像の表示
  - ランドマークの可視化（口の輪郭16点）
  - 計測値の表示（FPS、信頼度、開き具合、幅）
  - **母音判別結果の表示（メイン情報）**
  - シンプルで直感的なUI

## 技術要件

### T001: フロントエンド技術

#### T001-1: コア技術
- **必須**:
  - JavaScript (ES6+)
  - MediaPipe FaceMesh（npmパッケージ）
  - HTML5 MediaStream API（カメラアクセス）
  - Canvas API（可視化、オプション）

#### T001-2: モジュール形式
- **ES6 Modules**: `import/export`を使用
- **CommonJS対応**: 必要に応じて提供（将来的に）
- **TypeScript型定義**: `.d.ts`ファイルの提供（将来的に）

#### T001-3: フレームワーク対応
- **React**: React Hooksを使用したサンプルコード提供
- **Vue.js**: Composition APIを使用したサンプルコード提供（将来的に）
- **Vanilla JS**: 直接使用可能

### T002: パフォーマンス要件

#### T002-1: 動作環境
- **対象OS**: Windows 10/11, macOS, Linux
- **対象ブラウザ**: Chrome/Edge（最新版）, Firefox（最新版）, Safari（最新版）
- **最低スペック**:
  - CPU: Intel Core i5 相当以上
  - RAM: 8GB以上
  - カメラ: 720p解像度以上

#### T002-2: レスポンス要件
- **カメラ起動**: 3秒以内
- **顔検出**: 1秒以内
- **トラッキング遅延**: 100ms以内
- **フレームレート**: 30fps以上維持
- **母音判別処理**: 10ms以内（リアルタイム性を保つため）

### T003: セキュリティ・プライバシー要件

#### T003-1: プライバシー保護
- **ローカル処理**: カメラ映像はブラウザ内のみで処理（サーバー送信なし）
- **データ保存**: 個人を特定できる映像データの保存は最小限に
- **権限管理**: ユーザーへの明示的なカメラ権限要求

#### T003-2: データ管理
- **エクスポートデータ**: 座標値のみ（映像含まず）
- **設定データ**: ローカルストレージに保存可能（オプション）

## 非機能要件

### N001: ユーザビリティ
- **直感的なAPI**: シンプルで理解しやすいAPI設計
- **エラーハンドリング**: 分かりやすいエラーメッセージ
- **ドキュメント**: 充実したAPIドキュメントとサンプルコード

### N002: 保守性
- **コードの可読性**: 適切なコメントと命名規則
- **モジュール化**: 機能ごとに独立したモジュール
- **テストコード**: ユニットテストと統合テストの実装

### N003: 拡張性
- **プラグイン対応**: 将来的に他の判別機能（子音、感情等）を追加可能
- **カスタマイズ性**: 判別アルゴリズムの置き換えが可能な設計
- **多言語対応**: 将来的に他の言語の母音にも対応可能

### N004: 互換性
- **ブラウザ互換性**: モダンブラウザでの動作保証
- **デバイス互換性**: 様々なカメラデバイスに対応
- **フレームワーク互換性**: 主要なフレームワークで使用可能

## プロジェクト構造

### ディレクトリ構成

```
mouth-track/
├── module/                    # 再利用可能なモジュール
│   ├── core/                 # コア機能
│   │   ├── CameraManager.js  # カメラ管理
│   │   ├── FaceMeshHandler.js # MediaPipe統合
│   │   ├── MouthTracker.js   # トラッキング管理
│   │   ├── DataProcessor.js  # データ処理
│   │   └── VowelClassifier.js # 母音判別（新規）
│   ├── utils/                # ユーティリティ
│   │   ├── MouthLandmarks.js # ランドマーク定義
│   │   ├── Smoother.js       # 平滑化
│   │   └── ErrorHandler.js  # エラーハンドリング
│   ├── config/               # 設定
│   │   └── constants.js      # 定数定義
│   └── index.js              # モジュールエントリーポイント
│
├── demo/                      # 見本用のカメラ機能
│   ├── index.html            # デモHTML
│   ├── app.js                # デモアプリケーション
│   ├── css/                  # デモ用CSS
│   └── README.md             # デモの使い方
│
├── examples/                  # 使用例
│   ├── react/                # React使用例
│   │   ├── App.jsx
│   │   └── README.md
│   ├── vue/                  # Vue.js使用例（将来的に）
│   └── vanilla/              # Vanilla JS使用例
│
├── docs/                      # ドキュメント
│   ├── API.md                # APIリファレンス
│   ├── VOWEL_CLASSIFICATION.md # 母音判別の詳細
│   └── INTEGRATION.md        # 統合ガイド
│
├── tests/                     # テストコード
│   ├── unit/                 # ユニットテスト
│   └── integration/          # 統合テスト
│
├── package.json              # npm設定
├── README.md                 # プロジェクト概要
└── REQUIREMENTS.md           # 本要件定義書
```

### ファイルの役割

#### module/（モジュール）
- **目的**: 他のアプリケーションから使用する再利用可能なコード
- **特徴**: 
  - フレームワーク非依存
  - 最小限の依存関係
  - 明確なAPIインターフェース

#### demo/（デモ）
- **目的**: モジュールの動作確認とテスト
- **特徴**:
  - 完全な動作例
  - UI付きの見本アプリケーション
  - 開発時のデバッグツール

#### examples/（使用例）
- **目的**: 各フレームワークでの使用方法を示す
- **特徴**:
  - React、Vue.js等のサンプルコード
  - コピー&ペーストで使用可能
  - 各フレームワークのベストプラクティスに従う

## 母音判別の方法論

### 方法1: 相対判定方式（現在の実装）

#### 特徴量の使用
**正規化なし**で、生の計測値をそのまま使用する相対判定方式：
- **開き具合**: 生の距離値（通常0.01-0.15程度）
- **幅**: 生の距離値（通常0.03-0.15程度）
- **アスペクト比**: 幅/開き具合（絶対値）

#### 判別ルール
```javascript
// 疑似コード
function classifyVowel(metrics) {
  const { openness, width, aspectRatio } = metrics;
  
  // 正規化なしで、生の計測値をそのまま使用
  // 各母音のスコア計算（相対的な特徴量で判定）
  const scores = {
    'あ': calculateScoreA(openness, aspectRatio),
    'い': calculateScoreI(openness, width, aspectRatio),
    'う': calculateScoreU(openness, width, aspectRatio),
    'え': calculateScoreE(openness, width, aspectRatio),
    'お': calculateScoreO(openness, width, aspectRatio)
  };
  
  // 最高スコアの母音を返す
  return getMaxScoreVowel(scores);
}
```

#### 各母音の特徴量範囲（生の計測値）

| 母音 | 開き具合 | 幅 | アスペクト比 | 特徴 |
|------|---------|-----|------------|------|
| あ   | 0.06-0.15 | 0.05-0.12 | 0.5-0.8 | 大きく開く、縦長 |
| い   | 0.0-0.03 | 0.08-0.15 | 2.0-5.0 | 横に広げる、開きは小さい |
| う   | 0.0-0.02 | 0.03-0.06 | 1.5-3.0 | すぼめる、小さい |
| え   | 0.03-0.05 | 0.07-0.12 | 1.5-2.5 | 少し開いて横に広げる |
| お   | 0.05-0.08 | 0.05-0.10 | 0.9-1.5 | 丸く開ける、中程度 |

### 方法2: 機械学習ベース分類（将来的な拡張）

#### アプローチ
- **教師あり学習**: ユーザーが各母音を発音したデータを収集
- **特徴量エンジニアリング**: 開き具合、幅、アスペクト比、面積、変化率等
- **モデル**: 
  - 軽量: ロジスティック回帰、SVM
  - 高精度: ニューラルネットワーク（TensorFlow.js）

#### 実装の利点
- ユーザーごとの個体差に対応
- より高い精度
- 動的な学習（オンライン学習）

### 方法3: ハイブリッドアプローチ（将来的な拡張）

#### 現在の実装
- **相対判定方式**: 正規化なしで生の計測値を使用
- キャリブレーション不要で、個人差に対応

#### 将来的な拡張
- 機械学習モデルを追加
- ユーザーが選択可能（相対判定 or MLベース）

## 開発フェーズ

### フェーズ1: モジュール構造の再編成（現在）
- [ ] ディレクトリ構造の作成（module/, demo/, examples/）
- [ ] 既存コードのモジュールへの移動
- [ ] モジュールエントリーポイントの作成
- [ ] package.jsonの更新（exports設定）

### フェーズ2: 母音判別機能の実装
- [ ] `VowelClassifier.js`の作成
- [ ] 特徴量抽出ロジックの実装
- [ ] 閾値ベース分類の実装
- [ ] ユーザーキャリブレーション機能
- [ ] 判別結果のAPI提供

### フェーズ3: デモアプリケーションの作成
- [ ] demo/フォルダの作成
- [ ] カメラ機能のデモ実装
- [ ] 母音判別結果の可視化
- [ ] UI/UXの改善

### フェーズ4: React統合例の作成
- [ ] React Hooksを使用したサンプル
- [ ] カスタムフックの作成（`useMouthTracker`等）
- [ ] サンプルアプリケーションの作成

### フェーズ5: ドキュメント整備
- [ ] APIリファレンスの作成
- [ ] 母音判別の詳細ドキュメント
- [ ] 統合ガイドの作成
- [ ] サンプルコードの充実

### フェーズ6: テストと最適化
- [ ] ユニットテストの実装
- [ ] 統合テストの実装
- [ ] パフォーマンス最適化
- [ ] ブラウザ互換性テスト

## 技術的課題と対策

### 課題1: 個人差への対応
- **問題**: ユーザーごとに口のサイズや形状が異なる
- **対策**: 
  - **相対判定方式**: 正規化なしで生の計測値を使用し、相対的な特徴量で判定
  - キャリブレーション不要で、個人差に対応
  - 機械学習モデルの導入（将来的に）

### 課題2: リアルタイム性の維持
- **問題**: 母音判別処理が重いとフレームレートが低下
- **対策**:
  - 軽量な閾値ベース分類を初期実装
  - 処理の最適化（不要な計算の削減）
  - Web Workerでの並列処理（将来的に）

### 課題3: 判別精度の向上
- **問題**: 閾値ベースでは限界がある
- **対策**:
  - **高精度計測**: `MOUTH_CONTOUR_INDICES`（16点）を使用した詳細な計測
  - 複数の特徴量を組み合わせたスコアリング
  - 時間的な平滑化（連続フレームの考慮）
  - 機械学習モデルの導入（将来的に）

### 課題4: モジュールの汎用性
- **問題**: 様々なフレームワークで使用可能にする
- **対策**:
  - フレームワーク非依存なコア実装
  - 明確なAPIインターフェース
  - 各フレームワーク用のラッパー提供

## API設計（草案）

### モジュールの基本使用例

```javascript
// ES6 Modules
import { MouthTracker, VowelClassifier } from './module/index.js';

// 初期化
const tracker = new MouthTracker({
  videoElement: document.getElementById('video'),
  onDataUpdate: (data) => {
    console.log('Landmarks:', data.landmarks);
    console.log('Metrics:', data.metrics);
  }
});

// 母音判別の設定（相対判定方式）
const classifier = new VowelClassifier({
  thresholds: {
    // カスタム閾値（オプション、デフォルト値を使用する場合は省略可）
  },
  onVowelDetected: (result) => {
    console.log('Detected vowel:', result.vowel);
    console.log('Confidence:', result.confidence);
    console.log('Probabilities:', result.probabilities);
    console.log('Scores:', result.scores);
  }
});

// トラッキング開始
await tracker.initialize();
tracker.start();

// 母音判別を有効化
tracker.onDataUpdate((data) => {
  if (data.landmarks) {
    const vowelResult = classifier.classify(data.metrics);
    // onVowelDetected が自動的に呼ばれる
  }
});
```

### React使用例

```javascript
// useMouthTracker.js (カスタムフック)
import { useState, useEffect, useRef } from 'react';
import { MouthTracker, VowelClassifier } from 'mouth-track/module';

export function useMouthTracker(options = {}) {
  const [landmarks, setLandmarks] = useState(null);
  const [metrics, setMetrics] = useState(null);
  const [vowel, setVowel] = useState(null);
  const videoRef = useRef(null);
  const trackerRef = useRef(null);

  useEffect(() => {
    if (!videoRef.current) return;

    const tracker = new MouthTracker({
      videoElement: videoRef.current,
      onDataUpdate: (data) => {
        setLandmarks(data.landmarks);
        setMetrics(data.metrics);
      }
    });

    const classifier = new VowelClassifier({
      onVowelDetected: (result) => {
        setVowel(result);
      }
    });

    trackerRef.current = { tracker, classifier };

    tracker.initialize().then(() => {
      tracker.start();
    });

    return () => {
      tracker.stop();
    };
  }, []);

  return {
    videoRef,
    landmarks,
    metrics,
    vowel,
    start: () => trackerRef.current?.tracker.start(),
    stop: () => trackerRef.current?.tracker.stop()
  };
}

// App.jsx
import { useMouthTracker } from './useMouthTracker';

function App() {
  const { videoRef, landmarks, metrics, vowel } = useMouthTracker();

  return (
    <div>
      <video ref={videoRef} autoPlay playsInline />
      {vowel && (
        <div>
          <h2>検出された母音: {vowel.vowel}</h2>
          <p>信頼度: {(vowel.confidence * 100).toFixed(1)}%</p>
        </div>
      )}
    </div>
  );
}
```

## 成果物

1. **再利用可能なモジュール** (`module/`)
   - コア機能の実装
   - 明確なAPIインターフェース
   - ドキュメント

2. **デモアプリケーション** (`demo/`)
   - 動作確認用の見本アプリ
   - UI付きの完全な実装例

3. **使用例** (`examples/`)
   - React、Vue.js等のサンプルコード
   - 各フレームワークのベストプラクティス

4. **ドキュメント** (`docs/`)
   - APIリファレンス
   - 統合ガイド
   - 母音判別の詳細説明

5. **テストコード** (`tests/`)
   - ユニットテスト
   - 統合テスト

## 今後の展開可能性

- **多言語対応**: 英語、中国語等の母音にも対応
- **子音判別**: 子音の発音チェック機能
- **発音練習アプリ**: ゲーミフィケーション要素の追加
- **リハビリテーション支援**: 医療・福祉分野への応用
- **バーチャルアバター制御**: 口パクの自動生成
- **感情分析**: 口の動きから感情を推定

## まとめ

本プロジェクトは、口の動きトラッキングと母音判別機能を提供する、再利用可能なJavaScriptモジュールとして開発します。

**主要な特徴**:
1. **モジュール化**: 他のアプリケーションから簡単に組み込める
2. **母音判別**: 日本語の5つの母音を判別
3. **汎用性**: React、Vue.js等、様々なフレームワークで使用可能
4. **拡張性**: 将来的な機能追加に対応可能な設計

**開発の優先順位**:
1. モジュール構造の再編成
2. 母音判別機能の実装（閾値ベース）
3. デモアプリケーションの作成
4. React統合例の作成
5. ドキュメント整備
